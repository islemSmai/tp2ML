# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/114DUUOktXWjIQolnNkW3oZR062Y0n3QC

Q1 – How many positives samples are in positive_patches?
"""

from sklearn.datasets import fetch_lfw_people
faces = fetch_lfw_people()
positive_patches = faces.images

print(positive_patches.shape)

"""Q2– Show some positive samples (e.g., 16) (plt.subplot() and plt.imhsow())


"""

import matplotlib.pyplot as plt
for i in range (16):
  plt.subplot(4,4,i+1), plt.imshow(positive_patches[i,:,:],cmap='gray')

"""Q3- Try the Scikit-Image’s HOG extractor and visualize the oriented
gradients for a given
sample:
"""

from skimage import color, feature
import skimage.data
sample=positive_patches[1]
img = color.rgb2gray(sample) 
hog_vec, hog_vis = feature.hog(img, visualize=True)
plt.subplot(1,2,1),plt.imshow(sample,cmap='gray')
plt.subplot(1,2,2),plt.imshow(hog_vis,cmap='gray')
hog_vec.shape[0]
dim = hog_vec.shape[0]

"""To obtain a set of negative samples, we take any corpus of input images from Scikit-Image, and extract patches from them at a variety of scales as follows:"""

from skimage import data, transform
import numpy as np
from sklearn.feature_extraction.image import PatchExtractor
imgs_to_use = ['camera', 'text', 'coins', 'moon', 'page', 'clock', 'immunohistochemistry', 'chelsea', 'coffee', 'hubble_deep_field']
images = [color.rgb2gray(getattr(data, name)()) for name in imgs_to_use]
def extract_patches(img, N, scale=1.0, patch_size=positive_patches[0].shape):
        extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))
        extractor = PatchExtractor(patch_size=extracted_patch_size,
        max_patches=N, random_state=0)
        patches = extractor.transform(img[np.newaxis])
        if scale != 1:
                patches= np.array([transform.resize(patch, patch_size)
                for patch in patches])
        return patches
negative_patches = np.vstack([extract_patches(im, 1000, scale)
        for im in images for scale in [0.5, 1.0, 2.0]])

"""Q4 – How many negative samples are in negative_patches?"""

negative_patches.shape

"""Q5 – Show some negative samples (e.g., 16) (plt.subplot() and plt.imhsow())

"""

import matplotlib.pyplot as plt
for i in range (16):
  plt.subplot(4,4,i+1), plt.imshow(negative_patches[i,:,:],cmap='gray')

"""Q6 – Combine negative and positive sets (same number of samples in each set) and extract their HOG features to get data set X of size [n_samples, n_features].
 Q7 – Construct vector of labels y: 0 for all negative samples and 1 for all positive samples.
"""

N=min(positive_patches.shape[0],negative_patches.shape[0])
x= np.zeros((2*N, dim))
for i in range(N) :
    img=positive_patches[i,:,:]
    img_gray = color.rgb2gray(img)
    hog_vec= feature.hog(img_gray)
    x[i,:]= hog_vec.reshape((1,dim))
    y= np.concatenate((np.ones((N,1)),np.zeros((N,1))),axis=0)
for i in range(N) :
    img=negative_patches[i,:,:]
    img_gray = color.rgb2gray(img)
    hog_vec=feature.hog(img_gray)
    x[i+N,:]=hog_vec.reshape((1,dim))
    y= np.concatenate((np.ones((N,1)),np.zeros((N,1))),axis=0)

print(x.shape)
print(y.shape)

"""### 2. Binary Classification using Scikit-Learn"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
# View the shape of the data
X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""#### Build different binary classifiers with the best estimator

Then, we build different binary classifiers with the best estimator for 

each one:
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
models = [
        { "estimater": KNeighborsClassifier(),
        "params": {
                  "n_neighbors": [25], #,30,35,45
                  "weights": ['uniform'], #,'distance'
                  "leaf_size": [25], # ,30,35
                  "p": [1 ], #,2,3
                   }
        },
        { "estimater": DecisionTreeClassifier(),
        "params": {
                  "criterion": ['gini'], #,'entropy'
                  "splitter": ['best'], #,'random'
                  "max_depth": [None,90], #, 95,100
                  "max_features": [None, "auto"], #,"sqrt","log2"
                  "random_state": [42]
                  }
        },

        { "estimater": svm.SVC(),
        "params": {
                   'C': [0.1], # ,1, 10, 100, 1000
                   'gamma': [1], #,0.1,0.01,0.001,0.0001
                   'kernel': ['rbf']
                 }
        },
        { "estimater": RandomForestClassifier(),
        "params": {
                  "criterion": ['gini' ], #,'entropy'
                  "bootstrap": [True, False],
                  "max_depth": [85], #,90,95,100
                  "max_features": ['sqrt'], #,'log2'
                  "n_estimators": [60], # , 80, 90
                  "random_state": [42]
                  }
        }
]
column_names = ["KNeighbors"] # "DecisionTree", "SVM", "RF"
entries = []
max_acc = 0
best_model = None
for model in models:
      print(model["estimater"])
      # Create model
      clf = model["estimater"]
      # Instantiate the grid search model
      grid_search = GridSearchCV(estimator = clf, param_grid = model["params"],cv = 5)

      # Fit the model
      grid_search.fit(X_train, y_train);
      predicted = grid_search.predict(X_test)
      acc = accuracy_score(predicted, y_test)
      entries.append(acc)
      print(grid_search.best_params_)
      # Get the best model with the highest accuracy
      if acc > max_acc:
            max_acc = acc
            best_model = grid_search

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import statistics as st

plt.style.use('ggplot')

if len(column_names) != len(entries):
    # Append mean values to the list with smaller length
    if len(column_names) > len(entries):
        column_names = column_names[0:len(entries)]
    elif len(column_names) < len(entries):
        entries = entries[0:len(column_names)]



df = pd.DataFrame({"Estimator": column_names, "Accuracy": entries})
plt.figure(figsize=(8, 4))
sns.barplot(x='Estimator', y='Accuracy', data=df)
print(df)

"""3. Evaluating the Best Face Detector"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
def evaluate_preds(y_true, y_preds):
        """ Performs evaluation comparison on y_true labels vs. y_pred labels on a classification. """
        accuracy = accuracy_score(y_true, y_preds)
        precision = precision_score(y_true, y_preds, average='micro')
        recall = recall_score(y_true, y_preds, average='micro')
        f1 = f1_score(y_true, y_preds, average='micro')
        metric_dict = {"accuracy": round(accuracy, 2),
                    "precision": round(precision, 2),
                    "recall": round(recall, 2),
                    "f1": round(f1, 2)}
        return metric_dict

y_preds = best_model.predict(X_test)
dict_pref =evaluate_preds(y_test, y_preds)
print(dict_pref)

"""#4. Finding Faces in a New Image

Q10- Get a new test image by executing this script:
"""

test_image = skimage.data.astronaut()
test_image = skimage.color.rgb2gray(test_image)
test_image = skimage.transform.rescale(test_image, 0.5)
test_image = test_image[:160, 40:180]
plt.imshow(test_image, cmap='gray')
plt.axis('off');

"""Q11- Create a window that iterates over patches of this image, and compute 
HOG features for
each patch:
"""

def sliding_window(img, patch_size=positive_patches[0].shape,istep=2, jstep=2, scale=1.0):
  Ni, Nj = (int(scale * s) for s in patch_size)
  for i in range(0, img.shape[0] - Ni, istep):
          for j in range(0, img.shape[1] - Ni, jstep):
                            patch = img[i:i + Ni, j:j + Nj]
                            if scale != 1:
                                patch = transform.resize(patch, patch_size)
                            yield (i, j), patch
indices, patches = zip(*sliding_window(test_image))
patches_hog = np.array([feature.hog(patch) for patch in patches])

"""Q12- Use our face detector to evaluate whether each patch contains a face. What do you notice?"""

labels = best_model.predict(patches_hog)
labels.sum()

"""Q13- Draw face detected patches as rectangles:"""

fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')
Ni, Nj = positive_patches[0].shape
indices = np.array(indices)
for i, j in indices[labels == 1]:
        ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',alpha=0.3, lw=2, facecolor='none'))

import joblib as job 
job.dump(best_model,"rf_model.sav")

pip install streamlit

import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf

st.title('face detection')
st.markdown('Toy model to play to classify iris flowers into \ setosa, versicolor, virginica')

file = st.file_uploader("Please upload an brain scan file", type=["jpg", "png"])

import cv2
from PIL import Image, ImageOps
import numpy as np
st.set_option('deprecation.showfileUploaderEncoding', False)
def import_and_predict(image_data):
    
        size = (180,180)    
        image = ImageOps.fit(image_data, size, Image.ANTIALIAS)
        image = np.asarray(image)
        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        #img_resize = (cv2.resize(img, dsize=(75, 75),    interpolation=cv2.INTER_CUBIC))/255.
        
        img_reshape = img[np.newaxis,...]
        clf = joblib.load("rf_model.sav")
        prediction = clf.predict(img_reshape)
        
        return prediction
if file is None:
    st.text("Please upload an image file")
else:
    image = Image.open(file)
    st.image(image, use_column_width=True)
    predictions = import_and_predict(image)
    score = tf.nn.softmax(predictions[0])
    st.write(prediction)
    st.write(score)
    st.text(predictions[0])
    print(
    "This image most likely belongs to {} with a {:.2f} percent confidence."
    .format(class_names[np.argmax(score)], 100 * np.max(score))
    

)